{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "## Классификация FashionMNIST\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rc6WxZFxRsVn"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmRO_-jiRsVo"
      },
      "source": [
        "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mzs8RsjgRsVo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e4e8c95-f200-4608-e4a2-e96fc72de45e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-21 14:04:00--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
            "--2025-04-21 14:04:01--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6272446 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘hw_overfitting_data_dict.npy’\n",
            "\n",
            "hw_overfitting_data 100%[===================>]   5.98M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-04-21 14:04:01 (112 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yhtF4bw8RsVp"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mByhkdWiRsVp"
      },
      "outputs": [],
      "source": [
        "CUDA_DEVICE_ID = 0  # change if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = (\n",
        "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aYcL28OsgSq8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "99b48e34-6072-4700-dc5d-6112a6145b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 11.9MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 199kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.69MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 10.9MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 9')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "      self.dp_three = nn.Dropout(0.2)\n",
        "      self.dp_four = nn.Dropout(0.2)\n",
        "\n",
        "      self.bn_one = nn.BatchNorm2d(1)\n",
        "      self.conv1 = nn.Conv2d(1, 50, 3)\n",
        "      self.bn_two = nn.BatchNorm2d(50)\n",
        "      self.conv2 = nn.Conv2d(50, 100, 3)\n",
        "      self.bn_three = nn.BatchNorm2d(100)\n",
        "      self.conv3 = nn.Conv2d(100, 200, 3)\n",
        "      self.bn_four = nn.BatchNorm2d(200)\n",
        "\n",
        "      self.fc1 = nn.Linear(200, 100)\n",
        "      self.fc2 = nn.Linear(100, 50)\n",
        "      self.out = nn.Linear(50, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.bn_one(x)\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "\n",
        "    x = self.bn_two(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "\n",
        "\n",
        "    x = self.bn_three(x)\n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "\n",
        "    x = self.bn_four(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.dp_three(x)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.dp_four(x)\n",
        "    x = self.fc2(x)\n",
        "    x= F.relu(x)\n",
        "    return  self.out(x)"
      ],
      "metadata": {
        "id": "Jr74WDTfdYw-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "model_task_1 = Net()\n",
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Не забудьте перенести модель на выбранный `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Xas9SIXDoxvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b7dec62-0f92-4963-e590-ba36ee8152a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (dp_three): Dropout(p=0.2, inplace=False)\n",
              "  (dp_four): Dropout(p=0.2, inplace=False)\n",
              "  (bn_one): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv1): Conv2d(1, 50, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (bn_two): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(50, 100, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (bn_three): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(100, 200, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (bn_four): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc1): Linear(in_features=200, out_features=100, bias=True)\n",
              "  (fc2): Linear(in_features=100, out_features=50, bias=True)\n",
              "  (out): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "model_task_1.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_qMQzo1ggSq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d11caa61-6917-4ddc-a137-cd86f3a9ca4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJnU14bdnZa_"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model_task_1.parameters(), lr=0.003)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "fUIaGbqaloQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "YFi0xGfQloaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(10)):\n",
        "    model_task_1.train()\n",
        "    for i, data in enumerate(train_data_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_task_1(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model_task_1.eval()\n",
        "    loss_accumed = 0\n",
        "    for batch in test_data_loader:\n",
        "        output = model_task_1(batch[0].to(device))\n",
        "        loss = criterion(output, batch[1].to(device))\n",
        "        loss_accumed += loss\n",
        "    print(\"Epoch {} valid_loss {}\".format(epoch, loss_accumed))\n",
        "\n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prfJEEAVloer",
        "outputId": "69e48516-3e82-44f9-a6c2-478259d2d4c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [00:17<02:36, 17.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 valid_loss 123.56322479248047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:33<02:14, 16.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 valid_loss 109.86273193359375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:51<01:59, 17.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 valid_loss 102.9675521850586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [01:07<01:40, 16.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 valid_loss 105.06083679199219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [01:23<01:22, 16.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 valid_loss 99.00265502929688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [01:40<01:05, 16.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 valid_loss 97.18293762207031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [01:57<00:50, 16.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 valid_loss 99.45088958740234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [02:13<00:33, 16.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 valid_loss 133.7134246826172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [02:30<00:16, 16.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 valid_loss 90.27642822265625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [02:46<00:00, 16.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 valid_loss 91.39521789550781\n",
            "Training is finished!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8K6tcUeAloiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zce7gt1gSq-"
      },
      "source": [
        "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xua3TVZHgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cacdb01c-9ffb-49b3-ffc2-0e272541b924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.93583\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9KEKXBxgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e79f6f5-0398-4111-96c5-380b54db60a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.901\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAIrURCEgSq_"
      },
      "outputs": [],
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0uemqq4XEAS",
        "outputId": "34bf7119-a631-48ef-e7e4-6400d917cc5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "UJ7s4s-BX1tx",
        "outputId": "63636512-f212-4dd8-c75d-dd3e683916a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5c9556a8-0d87-4e7e-9c3d-0fa5ed8c46a6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5c9556a8-0d87-4e7e-9c3d-0fa5ed8c46a6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hw_fmnist_data_dict.npy to hw_fmnist_data_dict.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXWgwIMlRsVt"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MKnULZ8RsVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1629717-8120-4782-dfef-8ab77f5b557a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_fmnist_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_fmnist_data_dict.npy\"\n",
        "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_fmnist_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "}\n",
        "\n",
        "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('submission_dict_fmnist_task_1.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "cZyg8MewYK1Q",
        "outputId": "503bf9e2-d776-4b2e-88d7-83ad1b760660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7b70d801-0449-4e31-8f8d-2db01f5c4211\", \"submission_dict_fmnist_task_1.json\", 4061)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaIJOoxrRsVu"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_fmnist_task_1.json` в задачу Separation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}