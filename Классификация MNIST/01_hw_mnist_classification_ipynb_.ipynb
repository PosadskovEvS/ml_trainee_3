{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzAoo4ptMCOg"
      },
      "source": [
        "## Классификация MNIST\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wpO5EbJ_MCOi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhC9FYGiMCOj"
      },
      "source": [
        "Давайте обратимся к классической задаче распознавания рукописных цифр. Мы будем работать с набором данных [MNIST](http://yann.lecun.com/exdb/mnist/). В этом задании мы воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша основная задача: реализовать весь пайплайн обучения модели и добиться качества $\\geq 92\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбуку с первого занятия.\n",
        "\n",
        "Мы настоятельно рекомендуем писать код «с нуля», лишь изредка подглядывая в готовые примеры, а не просто «копировать-вставлять». Это поможет вам в будущем."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "Mnzv5wjmMCOj",
        "outputId": "a57a18c0-6e4a-41bb-db6c-a729482ffab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 123MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 43.1MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 96.9MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.63MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 1')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_mnist_data = MNIST('.', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "test_mnist_data = MNIST('.', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_mnist_data,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_mnist_data,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f'Image label: {_label}')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5opjPqEAMCOk"
      },
      "source": [
        "Постройте модель, представленную ниже. Пожалуйста, не создавайте чрезмерно сложную сеть — она не должна быть глубже четырёх слоёв (можно и меньше). Ваша основная задача — обучить модель и добиться как минимум 92% точности на тестовой выборке (hold-out выборке).\n",
        "\n",
        "*Примечание: линейных слоёв и функций активации должно быть достаточно.*\n",
        "\n",
        "__Обратите внимание, ваша модель должна быть представлена переменной `model`__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JO0evwfTUBjQ"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "      self.dp_three = nn.Dropout(0.2)\n",
        "      self.dp_four = nn.Dropout(0.2)\n",
        "\n",
        "      self.bn_one = nn.BatchNorm2d(1)\n",
        "      self.conv1 = nn.Conv2d(1, 30, 3)\n",
        "      self.bn_two = nn.BatchNorm2d(30)\n",
        "      self.conv2 = nn.Conv2d(30, 60, 3)\n",
        "      self.bn_three = nn.BatchNorm2d(60)\n",
        "      self.conv3 = nn.Conv2d(60, 120, 3)\n",
        "      self.bn_four = nn.BatchNorm2d(120)\n",
        "\n",
        "      self.fc1 = nn.Linear(120, 80)\n",
        "      self.fc2 = nn.Linear(80, 40)\n",
        "      self.out = nn.Linear(40, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.bn_one(x.view(x.size(0), 1, 28, 28))\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "\n",
        "    x = self.bn_two(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "\n",
        "\n",
        "    x = self.bn_three(x)\n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "\n",
        "    x = self.bn_four(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.dp_three(x)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.dp_four(x)\n",
        "    x = self.fc2(x)\n",
        "    x= F.relu(x)\n",
        "    return  self.out(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4dkZGX5kiUuu"
      },
      "outputs": [],
      "source": [
        "net = Net()\n",
        "#print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ywpb-GrAiua3"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clfurtZOiZ-G",
        "outputId": "a249d0d6-d9b3-4632-89ce-1231f1dfe2bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "       BatchNorm2d-1            [-1, 1, 28, 28]               2\n",
            "            Conv2d-2           [-1, 30, 26, 26]             300\n",
            "       BatchNorm2d-3           [-1, 30, 13, 13]              60\n",
            "            Conv2d-4           [-1, 60, 11, 11]          16,260\n",
            "       BatchNorm2d-5             [-1, 60, 5, 5]             120\n",
            "            Conv2d-6            [-1, 120, 3, 3]          64,920\n",
            "       BatchNorm2d-7            [-1, 120, 1, 1]             240\n",
            "           Dropout-8                  [-1, 120]               0\n",
            "            Linear-9                   [-1, 80]           9,680\n",
            "          Dropout-10                   [-1, 80]               0\n",
            "           Linear-11                   [-1, 40]           3,240\n",
            "           Linear-12                   [-1, 10]             410\n",
            "================================================================\n",
            "Total params: 95,232\n",
            "Trainable params: 95,232\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.28\n",
            "Params size (MB): 0.36\n",
            "Estimated Total Size (MB): 0.64\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(net.to(device), input_size=(28,28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lpaAZvo8MCOk"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "model = Net() # your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2O5wHa3m5Np",
        "outputId": "a61e9c97-ebd4-4559-8ca9-324d302c62db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (dp_three): Dropout(p=0.2, inplace=False)\n",
              "  (dp_four): Dropout(p=0.2, inplace=False)\n",
              "  (bn_one): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv1): Conv2d(1, 30, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (bn_two): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(30, 60, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (bn_three): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(60, 120, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (bn_four): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc1): Linear(in_features=120, out_features=80, bias=True)\n",
              "  (fc2): Linear(in_features=80, out_features=40, bias=True)\n",
              "  (out): Linear(in_features=40, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9DslbrHMCOl"
      },
      "source": [
        "Ниже доступны локальные тесты для проверки вашей модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFE9tPQKMCOl",
        "outputId": "f6701b42-a8fc-47ea-e34a-e8fc671dddad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model is not None, 'Please, use `model` variable to store your model'\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].reshape(-1, 784)\n",
        "    #x = random_batch[0]\n",
        "    y = random_batch[1]\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model(x)\n",
        "except Exception as e:\n",
        "    print('Something is wrong with the model')\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, 'Model should predict 10 logits/probas'\n",
        "\n",
        "print('Everything seems fine!')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME27t6hwMCOl"
      },
      "source": [
        "Обучите модель на обучающей выборке. Рекомендуем поэкспериментировать с различными оптимизаторами.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cCrLrZKMCOm"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "CLdVXwFKB4N5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "Jl9kYAcACkiN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(10)):\n",
        "    model.train()\n",
        "    for i, data in enumerate(train_data_loader, 0):\n",
        "        inputs, labels = data[0].reshape(-1, 784), data[1]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    loss_accumed = 0\n",
        "    for batch in test_data_loader:\n",
        "        output = model(batch[0].reshape(-1, 784))\n",
        "        loss = criterion(output, batch[1])\n",
        "        loss_accumed += loss\n",
        "    print(\"Epoch {} valid_loss {}\".format(epoch, loss_accumed))\n",
        "\n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji9P39-BB3Ni",
        "outputId": "843af3f0-a2ff-4a3c-cd43-b1f4626c58fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [01:38<14:44, 98.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 valid_loss 35.47028350830078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [03:17<13:11, 98.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 valid_loss 38.30595397949219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [04:51<11:16, 96.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 valid_loss 24.36804962158203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [06:24<09:31, 95.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 valid_loss 24.463266372680664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [07:58<07:52, 94.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 valid_loss 26.24110984802246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [09:33<06:18, 94.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 valid_loss 25.397785186767578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [11:06<04:42, 94.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 valid_loss 24.213743209838867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [12:47<03:13, 96.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 valid_loss 18.717857360839844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [14:21<01:35, 95.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 valid_loss 31.093189239501953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [15:54<00:00, 95.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 valid_loss 24.318647384643555\n",
            "Training is finished!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmktpzKDMCOm"
      },
      "source": [
        "Также помните, что вы всегда можете обратиться к отличной [документации](https://pytorch.org/docs/stable/index.html) и [учебным материалам](https://pytorch.org/tutorials/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVXCayfVMCOn"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCmROu2oMCOn"
      },
      "outputs": [],
      "source": [
        "predicted_labels = []\n",
        "real_labels = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in train_data_loader:\n",
        "        y_predicted = model(batch[0].reshape(-1, 784))\n",
        "        #y_predicted = model(batch[0])\n",
        "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
        "        real_labels.append(batch[1])\n",
        "\n",
        "predicted_labels = torch.cat(predicted_labels)\n",
        "real_labels = torch.cat(real_labels)\n",
        "train_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIW4vQ07MCOn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f73c94c-2aac-48cc-b811-b94fc99cda2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.98638\n"
          ]
        }
      ],
      "source": [
        "print(f'Neural network accuracy on train set: {train_acc:3.5}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0w34vdWMMCOn"
      },
      "outputs": [],
      "source": [
        "predicted_labels = []\n",
        "real_labels = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_data_loader:\n",
        "        y_predicted = model(batch[0].reshape(-1, 784))\n",
        "        #y_predicted = model(batch[0])\n",
        "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
        "        real_labels.append(batch[1])\n",
        "\n",
        "predicted_labels = torch.cat(predicted_labels)\n",
        "real_labels = torch.cat(real_labels)\n",
        "test_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ct9TkMFsMCOo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25afe4bc-54c7-4551-892a-029e39a707d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.9839\n"
          ]
        }
      ],
      "source": [
        "print(f'Neural network accuracy on test set: {test_acc:3.5}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riv3BpQyMCOo"
      },
      "source": [
        "Проверка, что пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5CFg-I3MCOo"
      },
      "outputs": [],
      "source": [
        "assert test_acc >= 0.92, 'Test accuracy is below 0.92 threshold'\n",
        "assert train_acc >= 0.91, 'Train accuracy is below 0.91 while test accuracy is fine. We recommend to check your model and data flow'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUhu8RGxJtj1",
        "outputId": "465a2cb1-266a-4135-9b95-379891bc4e98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "c7r9PRZfMLDT",
        "outputId": "948e8c43-5621-46a8-af46-aca8fe14e694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9befbc25-9f29-4984-975f-69d5d9f3b144\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9befbc25-9f29-4984-975f-69d5d9f3b144\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hw_mnist_data_dict.npy to hw_mnist_data_dict.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ismRxB2BMCOo"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model`, а файл `hw_mnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7B0obQDKMCOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8eea1c7-f367-4581-a515-e9029df6a923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_mnist_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import os\n",
        "import json\n",
        "assert os.path.exists('hw_mnist_data_dict.npy'), 'Please, download `hw_mnist_data_dict.npy` and place it in the working directory'\n",
        "\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            #y_predicted = model(eval_data[idx:idx+step].reshape(-1, 784))\n",
        "            y_predicted = model(eval_data[idx:idx+step].reshape(-1, 784))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1))\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels).numpy()\n",
        "    predicted_labels = ','.join([str(x) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "loaded_data_dict = np.load('hw_mnist_data_dict.npy', allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    'train': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['train'])),\n",
        "    'test': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['test']))\n",
        "}\n",
        "\n",
        "with open('submission_dict_mnist_task_1.json', 'w') as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print('File saved to `submission_dict_mnist_task_1.json`')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('submission_dict_mnist_task_1.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "O1GgLP_PQWBA",
        "outputId": "b0c67b13-56eb-46d7-9b00-e914babf6fbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b9028238-4279-4fef-8d2f-06473b189210\", \"submission_dict_mnist_task_1.json\", 4023)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pft76O3rMCOp"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_mnist_task_1.json` в задачу Warmup (hw_mnist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvFlcj6yMCOp"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "facelv_1.13+cu117",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}